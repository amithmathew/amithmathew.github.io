<!DOCTYPE html>
<html lang="en-us">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta http-equiv="X-Clacks-Overhead" content="GNU Terry Pratchett" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>When does a reranking step with RAG make sense? | Code and Contemplation</title>
<meta name="title" content="When does a reranking step with RAG make sense?" />
<meta name="description" content="A post on what reranking when using Retrieval Augmented Generation with LLMs is and when does it make sense to use this approach?" />
<meta name="keywords" content="RAG,LLM,rerank,ai," />


<meta property="og:title" content="When does a reranking step with RAG make sense?" />
<meta property="og:description" content="A post on what reranking when using Retrieval Augmented Generation with LLMs is and when does it make sense to use this approach?" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/when-does-a-reranking-step-with-rag-make-sense/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2024-03-20T10:59:38-04:00" />
<meta property="article:modified_time" content="2024-03-20T10:59:38-04:00" />



<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="When does a reranking step with RAG make sense?"/>
<meta name="twitter:description" content="A post on what reranking when using Retrieval Augmented Generation with LLMs is and when does it make sense to use this approach?"/>



<meta itemprop="name" content="When does a reranking step with RAG make sense?">
<meta itemprop="description" content="A post on what reranking when using Retrieval Augmented Generation with LLMs is and when does it make sense to use this approach?"><meta itemprop="datePublished" content="2024-03-20T10:59:38-04:00" />
<meta itemprop="dateModified" content="2024-03-20T10:59:38-04:00" />
<meta itemprop="wordCount" content="357">
<meta itemprop="keywords" content="RAG,LLM,rerank,ai," />
<meta name="referrer" content="no-referrer-when-downgrade" />

  <style>
  body {
    font-family: Verdana, sans-serif;
    margin: auto;
    padding: 20px;
    max-width: 720px;
    text-align: left;
    background-color: #fff;
    word-wrap: break-word;
    overflow-wrap: break-word;
    line-height: 1.5;
    color: #444;
  }

  h1,
  h2,
  h3,
  h4,
  h5,
  h6,
  strong,
  b {
    color: #222;
  }

  a {
    color: #3273dc;
     
  }

  .title {
    text-decoration: none;
    border: 0;
  }

  .title span {
    font-weight: 400;
  }

  nav a {
    margin-right: 10px;
  }

  textarea {
    width: 100%;
    font-size: 16px;
  }

  input {
    font-size: 16px;
  }

  content {
    line-height: 1.6;
  }

  table {
    width: 100%;
  }

  img {
    max-width: 100%;
  }

  code {
    padding: 2px 5px;
    background-color: #f2f2f2;
  }

  pre code {
    color: #222;
    display: block;
    padding: 20px;
    white-space: pre-wrap;
    font-size: 14px;
    overflow-x: auto;
  }

  div.highlight pre {
    background-color: initial;
    color: initial;
  }

  div.highlight code {
    background-color: unset;
    color: unset;
  }

  blockquote {
    border-left: 1px solid #999;
    color: #222;
    padding-left: 20px;
    font-style: italic;
  }

  footer {
    padding: 25px;
    text-align: center;
  }

  .helptext {
    color: #777;
    font-size: small;
  }

  .errorlist {
    color: #eba613;
    font-size: small;
  }

   
  ul.blog-posts {
    list-style-type: none;
    padding: unset;
  }

  ul.blog-posts li {
    display: flex;
  }

  ul.blog-posts li span {
    flex: 0 0 130px;
  }

  ul.blog-posts li a:visited {
    color: #8b6fcb;
  }

  @media (prefers-color-scheme: dark) {
    body {
      background-color: #333;
      color: #ddd;
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6,
    strong,
    b {
      color: #eee;
    }

    a {
      color: #8cc2dd;
    }

    code {
      background-color: #777;
    }

    pre code {
      color: #ddd;
    }

    blockquote {
      color: #ccc;
    }

    textarea,
    input {
      background-color: #252525;
      color: #ddd;
    }

    .helptext {
      color: #aaa;
    }
  }

</style>

</head>

<body>
  <header><a href="/" class="title">
  <h2>Code and Contemplation</h2>
</a>
<nav><a href="/">Home</a>

<a href="/helios">Helios Inc.</a>


<a href="/blog">Blog</a>

</nav>
</header>
  <main>

<h1>When does a reranking step with RAG make sense?</h1>
<p>
  <i>
    <time datetime='2024-03-20' pubdate>
      20 Mar, 2024
    </time>
  </i>
</p>

<content>
  <p>I was talking to a colleague about a RAG system he&rsquo;s evaluating and he mentioned that the architecture includes a reranking model. This sent me down a bit of a rabbit hole about rerankers and why reranking models make sense within the RAG architecture.</p>
<p>A typical RAG workflow looks like this.</p>
<pre class="mermaid">flowchart TD
    id1(Document Chunk)
    id2[[Embedding Model]]
    id3[( Vector DB )]
    id5(Query)
    id6[[Embedding Model]]
    llm[[LLM]]
    resp(LLM Response)

    id1-->id2-- Stored in -->id3
    id5-->id6-- Sent to -->id3
    subgraph sg1 [" "]
    id3-. Similarity Search .->id3
    end
    sg1-- Document Chunks -->llm
    id5-->llm
    llm-->resp
</pre>

<p>Reranking models make sense when you consider these assumptions -</p>
<ul>
<li>LLMs have limited context windows, restricting the amount of document chunks you can pass as context with your query.</li>
<li>Most LLMs have a &ldquo;Missing the Needle-in-the-haystack&rdquo; problem. I found the article <a href="https://arize.com/blog-course/the-needle-in-a-haystack-test-evaluating-the-performance-of-llm-rag-systems/">here</a> quite insightful, but the TL;DR is that when you have a heavily stuffed context window, LLMs can miss certain details within all the noise. With RAG, that detail may have been the most important detail needed to formulate a good response.</li>
<li>While Vector embeddings may live in the same (latent?) space as the actual LLMs (depends on the embedding model), the Vector similarity search is a crude approximation of what a model like an LLM can perform.</li>
</ul>
<p>Reranking models are closer to full-fledged LLMs than they are to vector search algorithms, and are able to incorporate more nuance.</p>
<p>Given these assumptions, reranking can be useful because not only can you reduce the amount of context (and thus noise) passed to the LLM, but your context is now more appropriate for the query that the LLM is trying to answer.</p>
<p>Your workflow will now look like -</p>
<pre class="mermaid">flowchart TD
    id1(Document Chunk)
    id2[[Embedding Model]]
    id3[( Vector DB )]
    id5(Query)
    id6[[Embedding Model]]
    llm[[LLM]]
    resp(LLM Response)

    id1-->id2-- Stored in -->id3
    id5-->id6-- Sent to -->id3
    subgraph sg1 [" "]
    id3-. Similarity Search .->id3
    end

    id7[[Reranking Model]]

    sg1-- Document Chunks -->id7
    id5-->id7
    id7-- Reranked Document Chunks, top-k -->llm
    id5-->llm
    llm-->resp
</pre>

<p>Cohere publishes benchmarks comparing what I&rsquo;m calling naive RAG against workflows including their rerank model <a href="https://txt.cohere.com/rerank/">here</a>, if you&rsquo;re interested in seeing how they compare. But overall, quite an interesting rabbit hole!</p>

</content>
<p>
  
  <a href="http://localhost:1313/blog/rag/">#Rag</a>
  
  <a href="http://localhost:1313/blog/llm/">#Llm</a>
  
  <a href="http://localhost:1313/blog/rerank/">#Rerank</a>
  
  <a href="http://localhost:1313/blog/ai/">#Ai</a>
  
</p>

  </main>
  <footer>
</footer>

    
</body>



</html>
